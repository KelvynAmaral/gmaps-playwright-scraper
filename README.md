<div align="center">

# üó∫Ô∏è GMaps Playwright Scraper  
### Modular Local Business Data Extraction Engine

<p>
  <img src="https://img.shields.io/badge/Python-3.9%2B-3776AB?style=for-the-badge&logo=python&logoColor=white"/>
  <img src="https://img.shields.io/badge/Playwright-Chromium%20Automation-2EAD33?style=for-the-badge&logo=playwright&logoColor=white"/>
  <img src="https://img.shields.io/badge/Architecture-Modular%20Layered-informational?style=for-the-badge"/>
  <img src="https://img.shields.io/badge/Status-Active-success?style=for-the-badge"/>
</p>

<p>
  Engine de scraping modular para extra√ß√£o estruturada  
  de dados p√∫blicos do Google Maps com persist√™ncia incremental  
  e consolida√ß√£o determin√≠stica.
</p>

</div>

---

#  Objetivo

Construir um **motor resiliente de coleta de dados geolocalizados**, com:

- Segmenta√ß√£o por bairro
- Extra√ß√£o baseada em renderiza√ß√£o real (Chromium)
- Estrat√©gias b√°sicas de mitiga√ß√£o de bloqueios
- Persist√™ncia tolerante a falhas
- Consolida√ß√£o determin√≠stica de resultados

---

#  Arquitetura Atual

O projeto segue uma **arquitetura modular em camadas**, com separa√ß√£o clara entre configura√ß√£o, orquestra√ß√£o, servi√ßos e modelo de dados.

```mermaid
flowchart LR

    A[config.py<br/>Configura√ß√µes Globais]
        --> B[main.py<br/>Orquestrador]

    B --> C[services/scraper_service.py<br/>Engine Playwright]
    B --> D[services/export_service.py<br/>Exporta√ß√£o CSV]

    C --> E[models/establishment.py<br/>Modelo de Dados]
    C --> F[output/*.csv]

    F --> G[juntar_dados.py<br/>Consolida√ß√£o e Deduplica√ß√£o]
```



#  Estrat√©gia T√©cnica

##  1. Navega√ß√£o Determin√≠stica

Evita intera√ß√£o excessiva com a UI sempre que poss√≠vel.  
As URLs de busca s√£o constru√≠das diretamente para reduzir depend√™ncia de cliques e heur√≠sticas fr√°geis.

---

##  2. Extra√ß√£o Baseada em Renderiza√ß√£o

Em vez de depender exclusivamente de atributos HTML inst√°veis:

- Captura texto renderizado na p√°gina
- Aplica Regex sobre o texto vis√≠vel
- Exemplo extra√≠do: `4,8 (1.205)`

Isso reduz quebras causadas por mudan√ßas estruturais frequentes do Google Maps.

---

##  3. Mitiga√ß√£o de Bloqueios

- User-Agent realista (Chrome / Windows)
- Scroll incremental
- Delays rand√¥micos
- Controle impl√≠cito de taxa por bairro

---

##  4. Persist√™ncia Incremental

Cada bairro gera um CSV independente.

Benef√≠cios:

- Recupera√ß√£o ap√≥s falha
- Execu√ß√£o interrompida n√£o perde dados anteriores
- Permite futura paraleliza√ß√£o

---

##  5. Deduplica√ß√£o Determin√≠stica

A consolida√ß√£o global utiliza a seguinte chave l√≥gica:

```
Nome + Endere√ßo
```

Isso reduz duplicidade entre bairros lim√≠trofes.

---

#  Estrutura do Projeto

```bash
gmaps-playwright-scraper/
‚îÇ
‚îú‚îÄ‚îÄ config.py                 # Configura√ß√µes globais do scraper
‚îú‚îÄ‚îÄ main.py                   # Orquestrador principal da execu√ß√£o
‚îú‚îÄ‚îÄ juntar_dados.py           # Consolida√ß√£o e deduplica√ß√£o
‚îú‚îÄ‚îÄ requirements.txt          # Depend√™ncias do projeto
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ establishment.py      # Representa√ß√£o da entidade coletada
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ scraper_service.py    # L√≥gica principal de scraping (Playwright)
‚îÇ   ‚îî‚îÄ‚îÄ export_service.py     # Exporta√ß√£o e manipula√ß√£o via Pandas
‚îÇ
‚îú‚îÄ‚îÄ output/                   # CSVs parciais e consolidados
‚îú‚îÄ‚îÄ scraper.log               # Log de execu√ß√£o
‚îî‚îÄ‚îÄ settings.json             # Configura√ß√µes auxiliares
```

---

# üß¨ Modelo de Dados

`Establishment`

| Campo     | Tipo   | Descri√ß√£o |
|-----------|--------|------------|
| nome      | str    | Nome do estabelecimento |
| endereco  | str    | Endere√ßo completo |
| telefone  | str    | Telefone p√∫blico |
| rating    | float  | Nota m√©dia |
| reviews   | int    | Quantidade de avalia√ß√µes |
| bairro    | str    | Bairro da coleta |
| categoria | str    | Termo pesquisado |

---

#  Configura√ß√£o

Arquivo: `config.py`

| Vari√°vel | Papel |
|----------|--------|
| `BAIRROS_BH` | Dom√≠nio geogr√°fico da coleta |
| `TERMOS` | Dom√≠nio de mercado (ex: pizzaria, academia) |
| `MAX_RESULTS_PER_CITY` | Controle de volume por execu√ß√£o |
| `HEADLESS` | Execu√ß√£o vis√≠vel ou silenciosa |

---

#  Execu√ß√£o

## 1Ô∏è‚É£ Instalar depend√™ncias

```bash
pip install -r requirements.txt
playwright install
```

## 2Ô∏è‚É£ Rodar coleta

```bash
python main.py
```

## 3Ô∏è‚É£ Consolidar dados

```bash
python juntar_dados.py
```

---

#  Pipeline de Execu√ß√£o

```mermaid
flowchart TD

    A[Carregar Configura√ß√£o] --> B[Iterar Bairros]
    B --> C[Iterar Termos]
    C --> D[Scraping via Playwright]

    D --> E[Normaliza√ß√£o de Dados]
    E --> F[Persist√™ncia CSV Parcial]

    F --> G[Consolida√ß√£o Global]
    G --> H[Deduplica√ß√£o Determin√≠stica]

    H --> I[CSV Consolidado Final]
```

---


# ‚ö†Ô∏è Considera√ß√µes Legais

Projeto destinado a:

- Educa√ß√£o
- Pesquisa de Mercado
- An√°lise de Dados P√∫blicos

O uso deve respeitar:

- Termos de Servi√ßo da plataforma
- Limites de requisi√ß√£o
- LGPD (Brasil) quando aplic√°vel

---

<div align="center">

### Engenharia modular aplicada a Web Scraping.

</div>